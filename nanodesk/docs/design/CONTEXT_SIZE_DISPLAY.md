# ä¸Šä¸‹æ–‡å¤§å°æ˜¾ç¤ºåŠŸèƒ½è®¾è®¡

> è®©ç”¨æˆ·å®æ—¶æŸ¥çœ‹å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆtoken æ•°é‡ï¼‰ï¼Œä¾¿äºç®¡ç†é•¿å¯¹è¯

**ææ¡ˆçŠ¶æ€**: ğŸ“ è®¾è®¡é˜¶æ®µ  
**ä¼˜å…ˆçº§**: ä½-ä¸­  
**å½±å“èŒƒå›´**: `nanobot/agent/loop.py`, `nanobot/agent/context.py`

---

## éœ€æ±‚æè¿°

### ç”¨æˆ·åœºæ™¯

```
ç”¨æˆ·: /context on                    â† å¼€å¯ä¸Šä¸‹æ–‡æ˜¾ç¤º
Agent: âœ… å·²å¼€å¯ä¸Šä¸‹æ–‡å¤§å°æ˜¾ç¤º

ç”¨æˆ·: å¸®æˆ‘åˆ†æè¿™ä¸ªä»£ç æ–‡ä»¶
Agent: [åˆ†æç»“æœ]
      ğŸ“Š ä¸Šä¸‹æ–‡: 2,847 tokens / çº¦ 11.4 KB

ç”¨æˆ·: ç»§ç»­åˆ†æå¦ä¸€ä¸ªæ–‡ä»¶...
Agent: [åˆ†æç»“æœ]
      ğŸ“Š ä¸Šä¸‹æ–‡: 8,932 tokens / çº¦ 35.7 KB  â† ç”¨æˆ·æ„è¯†åˆ°æ¥è¿‘ä¸Šé™

ç”¨æˆ·: /context off                   â† å…³é—­æ˜¾ç¤º
Agent: âœ… å·²å…³é—­ä¸Šä¸‹æ–‡å¤§å°æ˜¾ç¤º
```

### æ ¸å¿ƒéœ€æ±‚

| åŠŸèƒ½ | è¯´æ˜ |
|------|------|
| å¼€å…³æ§åˆ¶ | é»˜è®¤å…³é—­ï¼Œé€šè¿‡å‘½ä»¤ `/context on/off` åˆ‡æ¢ |
| æŒä¹…åŒ– | å¼€å¯ååœ¨åŒä¸€ä¼šè¯ä¸­æŒç»­æ˜¾ç¤º |
| æ˜¾ç¤ºä½ç½® | æ¯æ¡å›å¤æœ«å°¾é™„åŠ  token ä¿¡æ¯ |
| æ˜¾ç¤ºæ ¼å¼ | ç®€æ´ï¼Œä¸å¹²æ‰°ä¸»è¦å†…å®¹ |

---

## æŠ€æœ¯æ–¹æ¡ˆ

### Token è®¡ç®—æ–¹å¼

```python
# æ–¹æ¡ˆ 1: tiktoken (OpenAI å®˜æ–¹ï¼Œå‡†ç¡®)
import tiktoken

def count_tokens(messages: list[dict], model: str = "gpt-4") -> int:
    """è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„ token æ•°é‡"""
    try:
        encoding = tiktoken.encoding_for_model(model)
    except KeyError:
        encoding = tiktoken.get_encoding("cl100k_base")  # é»˜è®¤ç¼–ç 
    
    total = 0
    for msg in messages:
        # æ¯æ¡æ¶ˆæ¯çš„æ ¼å¼å¼€é”€
        total += 4  # <|im_start|>{role}\n{content}<|im_end|>\n
        
        if isinstance(msg["content"], str):
            total += len(encoding.encode(msg["content"]))
        elif isinstance(msg["content"], list):
            # å¤šæ¨¡æ€å†…å®¹ï¼ˆå›¾ç‰‡ç­‰ï¼‰
            for item in msg["content"]:
                if item.get("type") == "text":
                    total += len(encoding.encode(item["text"]))
                elif item.get("type") == "image_url":
                    total += 1000  # å›¾ç‰‡ä¼°ç®—å€¼
    
    return total
```

```python
# æ–¹æ¡ˆ 2: ç®€å•ä¼°ç®— (æ— éœ€é¢å¤–ä¾èµ–)
def estimate_tokens(messages: list[dict]) -> int:
    """
    ç®€å•ä¼°ç®— token æ•°é‡
    è‹±æ–‡çº¦ 1 token/å­—ï¼Œä¸­æ–‡çº¦ 2 tokens/å­—
    """
    total_chars = 0
    for msg in messages:
        content = msg.get("content", "")
        if isinstance(content, str):
            total_chars += len(content)
        elif isinstance(content, list):
            for item in content:
                if item.get("type") == "text":
                    total_chars += len(item["text"])
    
    # ç²—ç•¥ä¼°ç®—ï¼šå­—ç¬¦æ•° / 2.5
    return int(total_chars / 2.5)
```

**æ¨è**: æ–¹æ¡ˆ 1 (tiktoken) æ›´å‡†ç¡®ï¼Œå¯ä»¥æ·»åŠ ä¸ºå¯é€‰ä¾èµ–

---

### æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AgentLoop                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  process_messageâ”‚         â”‚   ContextMonitor     â”‚  â”‚
â”‚  â”‚                 â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚  â”‚ count_tokens() â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ build_ctx â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚           â”‚          â”‚  â”‚
â”‚  â”‚         â”‚       â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”â”‚         â”‚  â”‚ format_display() â”‚â”‚  â”‚
â”‚  â”‚  â”‚ send_resp   â”‚â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµ

```python
# 1. ç”¨æˆ·å¼€å¯æ˜¾ç¤º
user_message = "/context on"
â†’ session_manager.set_flag("show_context_size", True)
â†’ reply: "âœ… å·²å¼€å¯ä¸Šä¸‹æ–‡å¤§å°æ˜¾ç¤º"

# 2. æ­£å¸¸å¯¹è¯ï¼ˆå·²å¼€å¯ï¼‰
user_message = "å¸®æˆ‘åˆ†æä»£ç "
â†’ messages = context.build_messages(history, user_message)
â†’ token_count = count_tokens(messages)
â†’ response = llm.generate(messages)
â†’ response += f"\n\nğŸ“Š ä¸Šä¸‹æ–‡: {token_count:,} tokens"
â†’ send_reply(response)

# 3. ç”¨æˆ·å…³é—­æ˜¾ç¤º
user_message = "/context off"
â†’ session_manager.set_flag("show_context_size", False)
â†’ reply: "âœ… å·²å…³é—­ä¸Šä¸‹æ–‡å¤§å°æ˜¾ç¤º"
```

---

## è¯¦ç»†å®ç°

### 1. Token è®¡æ•°æ¨¡å—

```python
# nanobot/agent/token_counter.py
"""Token è®¡æ•°å·¥å…·ï¼Œæ”¯æŒå¤šç§æ¨¡å‹"""

from typing import Optional
import logging

logger = logging.getLogger(__name__)

# æ˜¯å¦å¯ç”¨ tiktoken
TIKTOKEN_AVAILABLE = False
try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    logger.debug("tiktoken not available, using estimation")


def count_tokens(messages: list[dict], model: Optional[str] = None) -> dict:
    """
    è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„ token æ•°é‡
    
    Returns:
        {
            "total": æ€» token æ•°,
            "system": ç³»ç»Ÿæ¶ˆæ¯ tokens,
            "history": å†å²æ¶ˆæ¯ tokens,
            "current": å½“å‰æ¶ˆæ¯ tokens,
            "method": "tiktoken" or "estimate"
        }
    """
    if TIKTOKEN_AVAILABLE:
        return _count_with_tiktoken(messages, model)
    else:
        return _count_with_estimate(messages)


def _count_with_tiktoken(messages: list[dict], model: Optional[str]) -> dict:
    """ä½¿ç”¨ tiktoken ç²¾ç¡®è®¡ç®—"""
    try:
        encoding = tiktoken.encoding_for_model(model or "gpt-4")
    except KeyError:
        encoding = tiktoken.get_encoding("cl100k_base")
    
    result = {"total": 0, "system": 0, "history": 0, "current": 0, "method": "tiktoken"}
    
    for i, msg in enumerate(messages):
        tokens = _encode_message(msg, encoding)
        result["total"] += tokens
        
        # åˆ†ç±»ç»Ÿè®¡
        if msg.get("role") == "system":
            result["system"] += tokens
        elif i == len(messages) - 1 and msg.get("role") == "user":
            result["current"] += tokens
        else:
            result["history"] += tokens
    
    return result


def _count_with_estimate(messages: list[dict]) -> dict:
    """ç®€å•ä¼°ç®—ï¼ˆæ— éœ€ tiktokenï¼‰"""
    result = {"total": 0, "system": 0, "history": 0, "current": 0, "method": "estimate"}
    
    for i, msg in enumerate(messages):
        content = msg.get("content", "")
        if isinstance(content, str):
            # è‹±æ–‡çº¦ 0.25 tokens/charï¼Œä¸­æ–‡çº¦ 0.5 tokens/char
            # ç²—ç•¥å¹³å‡ï¼šchars / 2.5
            tokens = max(1, int(len(content) / 2.5))
        elif isinstance(content, list):
            tokens = 0
            for item in content:
                if item.get("type") == "text":
                    tokens += max(1, int(len(item.get("text", "")) / 2.5))
                elif item.get("type") == "image_url":
                    tokens += 1000  # å›¾ç‰‡ä¼°ç®—
        else:
            tokens = 0
        
        result["total"] += tokens
        
        if msg.get("role") == "system":
            result["system"] += tokens
        elif i == len(messages) - 1 and msg.get("role") == "user":
            result["current"] += tokens
        else:
            result["history"] += tokens
    
    return result


def _encode_message(msg: dict, encoding) -> int:
    """ç¼–ç å•æ¡æ¶ˆæ¯"""
    tokens = 4  # æ¶ˆæ¯æ ¼å¼å¼€é”€ <|im_start|>role\n
    
    content = msg.get("content", "")
    if isinstance(content, str):
        tokens += len(encoding.encode(content))
    elif isinstance(content, list):
        for item in content:
            if item.get("type") == "text":
                tokens += len(encoding.encode(item["text"]))
            elif item.get("type") == "image_url":
                # å›¾ç‰‡ token è®¡ç®—å¤æ‚ï¼Œä¼°ç®— 1000
                tokens += 1000
    
    tokens += 2  # <|im_end|>\n
    return tokens


def format_display(token_info: dict) -> str:
    """æ ¼å¼åŒ–æ˜¾ç¤º token ä¿¡æ¯"""
    total = token_info["total"]
    method = token_info["method"]
    
    # ä¼°ç®— KBï¼ˆçº¦ 4 bytes/tokenï¼‰
    kb = total * 4 / 1024
    
    # ä¸åŒæ¨¡å‹çš„ä¸Šä¸‹æ–‡ä¸Šé™æç¤º
    if total > 120000:
        warning = " âš ï¸æ¥è¿‘ä¸Šé™"
    elif total > 80000:
        warning = " ğŸŸ¡æ³¨æ„"
    else:
        warning = ""
    
    method_note = "~" if method == "estimate" else ""
    
    return f"ğŸ“Š ä¸Šä¸‹æ–‡: {method_note}{total:,} tokens / {method_note}{kb:.1f} KB{warning}"
```

### 2. å‘½ä»¤å¤„ç†

```python
# nanobot/agent/loop.py

async def _process_message(self, msg: InboundMessage) -> OutboundMessage | None:
    # ... ç°æœ‰ä»£ç  ...
    
    # å¤„ç† /context å‘½ä»¤
    if msg.content.strip() == "/context on":
        self.session_manager.set_session_flag(
            msg.channel, msg.chat_id, "show_context_size", True
        )
        return OutboundMessage(
            channel=msg.channel,
            chat_id=msg.chat_id,
            content="âœ… å·²å¼€å¯ä¸Šä¸‹æ–‡å¤§å°æ˜¾ç¤º\n\n"
                   "ğŸ’¡ æç¤ºï¼šæ¯æ¡å›å¤æœ«å°¾å°†æ˜¾ç¤ºå½“å‰å¯¹è¯çš„ token æ•°é‡\n"
                   "   å‘é€ `/context off` å…³é—­æ˜¾ç¤º"
        )
    
    if msg.content.strip() == "/context off":
        self.session_manager.set_session_flag(
            msg.channel, msg.chat_id, "show_context_size", False
        )
        return OutboundMessage(
            channel=msg.channel,
            chat_id=msg.chat_id,
            content="âœ… å·²å…³é—­ä¸Šä¸‹æ–‡å¤§å°æ˜¾ç¤º"
        )
    
    # ... æ­£å¸¸å¤„ç†æµç¨‹ ...
```

### 3. å›å¤é™„åŠ  token ä¿¡æ¯

```python
# nanobot/agent/loop.py

async def _generate_response(self, messages: list[dict], msg: InboundMessage) -> str:
    """ç”Ÿæˆå›å¤ï¼Œå¯èƒ½é™„åŠ  token ä¿¡æ¯"""
    
    # è°ƒç”¨ LLM ç”Ÿæˆå›å¤
    response = await self.provider.generate(messages)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ˜¾ç¤ºä¸Šä¸‹æ–‡å¤§å°
    show_context = self.session_manager.get_session_flag(
        msg.channel, msg.chat_id, "show_context_size", default=False
    )
    
    if show_context:
        from nanobot.agent.token_counter import count_tokens, format_display
        
        token_info = count_tokens(messages, model=self.model)
        display = format_display(token_info)
        
        # é™„åŠ åˆ°å›å¤æœ«å°¾
        response += f"\n\n{display}"
    
    return response
```

---

## é…ç½®é€‰é¡¹

```python
# nanobot/config/schema.py

class AgentConfig(BaseModel):
    """Agent é…ç½®"""
    
    # ... ç°æœ‰é…ç½® ...
    
    enable_context_size_display: bool = True
    """æ˜¯å¦å¯ç”¨ /context å‘½ä»¤åŠŸèƒ½"""
    
    context_size_warning_threshold: int = 80000
    """token æ•°é‡è­¦å‘Šé˜ˆå€¼ï¼ˆé»„è‰²æé†’ï¼‰"""
    
    context_size_critical_threshold: int = 120000
    """token æ•°é‡å±é™©é˜ˆå€¼ï¼ˆçº¢è‰²è­¦å‘Šï¼‰"""
```

---

## ç”¨æˆ·ç•Œé¢

### å‘½ä»¤æ ¼å¼

```
/context on       # å¼€å¯æ˜¾ç¤º
/context off      # å…³é—­æ˜¾ç¤º  
/context status   # æŸ¥çœ‹å½“å‰çŠ¶æ€
```

### æ˜¾ç¤ºæ ·å¼

**æ­£å¸¸çŠ¶æ€**:
```
ğŸ“Š ä¸Šä¸‹æ–‡: 2,847 tokens / 11.1 KB
```

**æ¥è¿‘ä¸Šé™** (é»„è‰²):
```
ğŸŸ¡ ä¸Šä¸‹æ–‡: 85,432 tokens / 333.7 KB
```

**æ¥è¿‘ä¸Šé™** (çº¢è‰²ï¼Œä½¿ç”¨ä¼°ç®—):
```
âš ï¸ ä¸Šä¸‹æ–‡: ~125,600 tokens / ~490.6 KB
```

---

## ä¾èµ–ç®¡ç†

```toml
# pyproject.toml
[project.optional-dependencies]
tiktoken = ["tiktoken>=0.5.0"]
all = ["tiktoken>=0.5.0", ...]
```

```python
# å®‰è£…æ—¶æç¤º
"""
tiktoken not available, using estimation.
For accurate token counting, install with:
    pip install tiktoken
"""
```

---

## å®æ–½æ­¥éª¤

```
Phase 1: æ ¸å¿ƒåŠŸèƒ½ (1 å¤©)
â”œâ”€â”€ åˆ›å»º token_counter.py æ¨¡å—
â”‚   â””â”€â”€ æ”¯æŒ tiktoken å’Œä¼°ç®—ä¸¤ç§æ¨¡å¼
â”œâ”€â”€ å®ç° /context on/off å‘½ä»¤
â””â”€â”€ åœ¨å›å¤æœ«å°¾é™„åŠ  token ä¿¡æ¯

Phase 2: ä¼˜åŒ– (0.5 å¤©)
â”œâ”€â”€ åˆ†ç±»ç»Ÿè®¡ (system/history/current)
â”œâ”€â”€ é˜ˆå€¼è­¦å‘Šé¢œè‰²
â””â”€â”€ æ·»åŠ  tiktoken ä¸ºå¯é€‰ä¾èµ–

Phase 3: å®Œå–„ (0.5 å¤©)
â”œâ”€â”€ æŒä¹…åŒ–å¼€å…³çŠ¶æ€
â”œâ”€â”€ /context status å‘½ä»¤
â””â”€â”€ æ–‡æ¡£å’Œç¤ºä¾‹
```

---

## éªŒæ”¶æ ‡å‡†

- [ ] `/context on` å¼€å¯åï¼Œæ¯æ¡å›å¤æ˜¾ç¤º token æ•°é‡
- [ ] `/context off` å…³é—­æ˜¾ç¤º
- [ ] æœªå®‰è£… tiktoken æ—¶ä½¿ç”¨ä¼°ç®—æ¨¡å¼ï¼Œæ˜¾ç¤º "~"
- [ ] è¶…è¿‡é˜ˆå€¼æ—¶æ˜¾ç¤ºè­¦å‘Šé¢œè‰²
- [ ] å¼€å…³çŠ¶æ€åœ¨åŒä¸€ä¼šè¯ä¸­æŒä¹…åŒ–
- [ ] ä¸å½±å“æ­£å¸¸å¯¹è¯æ€§èƒ½ï¼ˆè®¡æ•° < 10msï¼‰

---

## æ³¨æ„äº‹é¡¹

1. **æ€§èƒ½**: token è®¡æ•°ä¸åº”æ˜¾è‘—å½±å“å“åº”æ—¶é—´ï¼ˆç›®æ ‡ < 10msï¼‰
2. **éšç§**: token è®¡æ•°æœ¬åœ°å®Œæˆï¼Œä¸å‘é€é¢å¤–è¯·æ±‚
3. **å…¼å®¹æ€§**: æ”¯æŒæ–‡æœ¬å’Œå¤šæ¨¡æ€æ¶ˆæ¯
4. **å¯é€‰ä¾èµ–**: tiktoken ä½œä¸ºå¯é€‰ï¼Œæ— ä¾èµ–æ—¶é™çº§ä¼°ç®—

---

**ä¸‹ä¸€æ­¥**: ç¡®è®¤éœ€æ±‚ç»†èŠ‚åï¼Œå¯ä» Phase 1 å¼€å§‹å®ç°
